{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oliver-Borg/RLEx1/blob/main/L171_Exercise_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# L171 - Exercise 1: Solving a Rubik's cube with Deep Q-Learning\n",
        "\n",
        "Welcome to the first exercise for L171: Reinforcement Learning class!\n",
        "\n",
        "Today, we will work through practical exercises on Deep Q-learning (DQN) to apply the concepts you have learnt in class. Completing these exercises is important preparation for both your tests and the mini-project.\n",
        "\n",
        "> ❗ IMPORTANT: will discuss these exercises in class on **27/10/2025** (week 3). You do **not** need to submit anything.\n",
        "\n",
        "While we cannot give you the answers before our class meeting, you are encouraged to discuss the exercise with your friends."
      ],
      "metadata": {
        "id": "LfXQdfaq1FdP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvyGCsgSCxHQ"
      },
      "source": [
        "# Installation Part 1 - Read CAREFULLY❗\n",
        "\n",
        "**First: Set Your Runtime to GPU**\n",
        "\n",
        "Before you do anything else, you must enable GPU acceleration.\n",
        "1) In the top menu, navigate to Runtime → Change runtime type.\n",
        "2) A pop-up window will appear. Find the \"Hardware accelerator\" dropdown menu and select GPU.\n",
        "3) Click Save.\n",
        "\n",
        "------\n",
        "\n",
        "**Second: Run This Cell (~1 min) and Restart the Session**\n",
        "\n",
        "Now, you can run this installation cell. After it finishes, a message will appear prompting you to restart the session.\n",
        "\n",
        "⚠️ You MUST restart the session. Click the ❗ \"Restart session\" button ❗ when it appears. Do not run this installation cell again. After the session has restarted, simply move on to the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u4W-Yt5qsuNS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b6059714-11c0-4c5d-f5fe-e40d2d464c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_p4T016W1_YUGU8S1FyarJPmUxiSsyZM\n",
            "To: /content/rl171-ex1.zip\n",
            "\r  0% 0.00/55.1k [00:00<?, ?B/s]\r100% 55.1k/55.1k [00:00<00:00, 6.28MB/s]\n",
            "Archive:  /content/rl171-ex1.zip\n",
            "  inflating: /content/rl171-ex1/pyproject.toml  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/._pyproject.toml  \n",
            "   creating: /content/rl171-ex1/rl171/\n",
            "  inflating: /content/rl171-ex1/__MACOSX/._rl171  \n",
            "   creating: /content/rl171-ex1/rl171/cube_utils/\n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/._cube_utils  \n",
            "  inflating: /content/rl171-ex1/rl171/mujoco_env_cube_only.py  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/._mujoco_env_cube_only.py  \n",
            "  inflating: /content/rl171-ex1/rl171/README.md  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/._README.md  \n",
            "   creating: /content/rl171-ex1/rl171/assets/\n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/._assets  \n",
            "  inflating: /content/rl171-ex1/rl171/cube_utils/mujoco_xml.py  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/cube_utils/._mujoco_xml.py  \n",
            "  inflating: /content/rl171-ex1/rl171/cube_utils/mujoco_cube_helpers.py  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/cube_utils/._mujoco_cube_helpers.py  \n",
            "  inflating: /content/rl171-ex1/rl171/cube_utils/cube_manipulator.py  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/cube_utils/._cube_manipulator.py  \n",
            "  inflating: /content/rl171-ex1/rl171/cube_utils/rotation.py  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/cube_utils/._rotation.py  \n",
            "   creating: /content/rl171-ex1/rl171/assets/mesh/\n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/._mesh  \n",
            "   creating: /content/rl171-ex1/rl171/assets/textures/\n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/._textures  \n",
            "   creating: /content/rl171-ex1/rl171/assets/xmls/\n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/._xmls  \n",
            "   creating: /content/rl171-ex1/rl171/assets/mesh/rubiks_cube/\n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/mesh/._rubiks_cube  \n",
            "   creating: /content/rl171-ex1/rl171/assets/textures/cube/\n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/._cube  \n",
            "   creating: /content/rl171-ex1/rl171/assets/xmls/rubiks_cube/\n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/xmls/._rubiks_cube  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/mesh/rubiks_cube/roundcube.msh  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/mesh/rubiks_cube/._roundcube.msh  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material121.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material121.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material120.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material120.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material122.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material122.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material022.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material022.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material220.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material220.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material221.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material221.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material021.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material021.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material222.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material222.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material020.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material020.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material011.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material011.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material212.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material212.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material010.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material010.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material012.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material012.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material210.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material210.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material211.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material211.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material201.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material201.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material200.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material200.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material002.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material002.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material000.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material000.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material202.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material202.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material001.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material001.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material112.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material112.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material111.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material111.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material110.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material110.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material100.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material100.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material101.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material101.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/textures/cube/material102.png  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/textures/cube/._material102.png  \n",
            "  inflating: /content/rl171-ex1/rl171/assets/xmls/rubiks_cube/scene_rubik_perpendicular_only.xml  \n",
            "  inflating: /content/rl171-ex1/__MACOSX/rl171/assets/xmls/rubiks_cube/._scene_rubik_perpendicular_only.xml  \n",
            "Obtaining file:///content/rl171-ex1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencv-python==4.9.0.80 (from rl171==2025.0.0)\n",
            "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy==1.26.4 (from rl171==2025.0.0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qpsolvers[quadprog] (from rl171==2025.0.0)\n",
            "  Downloading qpsolvers-4.8.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mujoco==3.2.4 (from rl171==2025.0.0)\n",
            "  Downloading mujoco-3.2.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pin==2.7.0 (from rl171==2025.0.0)\n",
            "  Downloading pin-2.7.0-2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (20 kB)\n",
            "Collecting ruckig==0.12.2 (from rl171==2025.0.0)\n",
            "  Downloading ruckig-0.12.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Collecting mink==0.0.13 (from rl171==2025.0.0)\n",
            "  Downloading mink-0.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting flask==3.0.2 (from rl171==2025.0.0)\n",
            "  Downloading flask-3.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting flask_socketio==5.3.6 (from rl171==2025.0.0)\n",
            "  Downloading Flask_SocketIO-5.3.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pyzmq>=25.1.2 in /usr/local/lib/python3.12/dist-packages (from rl171==2025.0.0) (26.2.1)\n",
            "Collecting redis==5.0.6 (from rl171==2025.0.0)\n",
            "  Downloading redis-5.0.6-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting phoenix6==25.3.2 (from rl171==2025.0.0)\n",
            "  Downloading phoenix6-25.3.2-cp310-abi3-manylinux_2_35_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pygame>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from rl171==2025.0.0) (2.6.1)\n",
            "Collecting viser==0.2.6 (from rl171==2025.0.0)\n",
            "  Downloading viser-0.2.6-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting yourdfpy==0.0.56 (from rl171==2025.0.0)\n",
            "  Downloading yourdfpy-0.0.56-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting tyro==0.9.13 (from rl171==2025.0.0)\n",
            "  Downloading tyro-0.9.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting pycuber==0.2.2 (from rl171==2025.0.0)\n",
            "  Downloading pycuber-0.2.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting gymnasium==0.29.1 (from rl171==2025.0.0)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting matplotlib==3.10.6 (from rl171==2025.0.0)\n",
            "  Downloading matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from rl171==2025.0.0) (2.8.0+cu126)\n",
            "Collecting tensorboard==2.20.0 (from rl171==2025.0.0)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.2->rl171==2025.0.0) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.2->rl171==2025.0.0) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.2->rl171==2025.0.0) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.2->rl171==2025.0.0) (8.3.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.2->rl171==2025.0.0) (1.9.0)\n",
            "Collecting python-socketio>=5.0.2 (from flask_socketio==5.3.6->rl171==2025.0.0)\n",
            "  Downloading python_socketio-5.14.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1->rl171==2025.0.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1->rl171==2025.0.0) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1->rl171==2025.0.0) (0.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6->rl171==2025.0.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6->rl171==2025.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6->rl171==2025.0.0) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6->rl171==2025.0.0) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6->rl171==2025.0.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6->rl171==2025.0.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6->rl171==2025.0.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6->rl171==2025.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mujoco==3.2.4->rl171==2025.0.0) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.12/dist-packages (from mujoco==3.2.4->rl171==2025.0.0) (1.13.0)\n",
            "Collecting glfw (from mujoco==3.2.4->rl171==2025.0.0)\n",
            "  Downloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.12/dist-packages (from mujoco==3.2.4->rl171==2025.0.0) (3.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from phoenix6==25.3.2->rl171==2025.0.0) (75.2.0)\n",
            "Collecting cmeel (from pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading cmeel-0.57.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting cmeel-boost~=1.83.0 (from pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading cmeel_boost-1.83.0-0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1000 bytes)\n",
            "Collecting cmeel-urdfdom<4,>=3.1.1.1 (from pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading cmeel_urdfdom-3.1.1.1-0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting hpp-fcl<4,>=2.3.4 (from pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading hpp_fcl-2.4.4-3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.20.0->rl171==2025.0.0) (1.75.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.20.0->rl171==2025.0.0) (3.9)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.20.0->rl171==2025.0.0) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.20.0->rl171==2025.0.0) (0.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->rl171==2025.0.0) (3.4.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro==0.9.13->rl171==2025.0.0) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro==0.9.13->rl171==2025.0.0) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro==0.9.13->rl171==2025.0.0)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro==0.9.13->rl171==2025.0.0) (4.4.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from viser==0.2.6->rl171==2025.0.0) (15.0.1)\n",
            "Collecting msgspec>=0.18.6 (from viser==0.2.6->rl171==2025.0.0)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: imageio>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from viser==0.2.6->rl171==2025.0.0) (2.37.0)\n",
            "Requirement already satisfied: scikit-image>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from viser==0.2.6->rl171==2025.0.0) (0.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.12/dist-packages (from viser==0.2.6->rl171==2025.0.0) (1.16.2)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from viser==0.2.6->rl171==2025.0.0) (4.67.1)\n",
            "Collecting trimesh>=3.21.7 (from viser==0.2.6->rl171==2025.0.0)\n",
            "  Downloading trimesh-4.9.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting nodeenv>=1.8.0 (from viser==0.2.6->rl171==2025.0.0)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: psutil>=5.9.5 in /usr/local/lib/python3.12/dist-packages (from viser==0.2.6->rl171==2025.0.0) (5.9.5)\n",
            "Collecting plyfile>=1.0.2 (from viser==0.2.6->rl171==2025.0.0)\n",
            "  Downloading plyfile-1.1.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyliblzfse>=0.4.1 (from viser==0.2.6->rl171==2025.0.0)\n",
            "  Downloading pyliblzfse-0.4.1.tar.gz (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from yourdfpy==0.0.56->rl171==2025.0.0) (5.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from yourdfpy==0.0.56->rl171==2025.0.0) (1.17.0)\n",
            "Collecting quadprog>=0.1.11 (from qpsolvers[quadprog]->rl171==2025.0.0)\n",
            "  Downloading quadprog-0.1.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting cmeel-console-bridge (from cmeel-urdfdom<4,>=3.1.1.1->pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading cmeel_console_bridge-1.0.2.3-0-py3-none-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting cmeel-tinyxml (from cmeel-urdfdom<4,>=3.1.1.1->pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading cmeel_tinyxml-2.6.2.3-0-py3-none-manylinux_2_28_x86_64.whl.metadata (389 bytes)\n",
            "Collecting cmeel-assimp<6,>=5.3.1 (from hpp-fcl<4,>=2.3.4->pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading cmeel_assimp-5.4.3.1-0-py3-none-manylinux_2_28_x86_64.whl.metadata (968 bytes)\n",
            "Collecting cmeel-octomap<2,>=1.9.8.2 (from hpp-fcl<4,>=2.3.4->pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading cmeel_octomap-1.10.0-5-py3-none-manylinux_2_28_x86_64.whl.metadata (983 bytes)\n",
            "Collecting cmeel-qhull<8.0.3,>=8.0.2.1 (from hpp-fcl<4,>=2.3.4->pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading cmeel_qhull-8.0.2.1-1-py3-none-manylinux_2_28_x86_64.whl.metadata (838 bytes)\n",
            "Collecting eigenpy<4,>=3.1 (from hpp-fcl<4,>=2.3.4->pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading eigenpy-3.12.0-1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=3.1.2->flask==3.0.2->rl171==2025.0.0) (3.0.3)\n",
            "Collecting bidict>=0.21.0 (from python-socketio>=5.0.2->flask_socketio==5.3.6->rl171==2025.0.0)\n",
            "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting python-engineio>=4.11.0 (from python-socketio>=5.0.2->flask_socketio==5.3.6->rl171==2025.0.0)\n",
            "  Downloading python_engineio-4.12.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting daqp>=0.5.1 (from qpsolvers[daqp]>=4.3.1->mink==0.0.13->rl171==2025.0.0)\n",
            "  Downloading daqp-0.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro==0.9.13->rl171==2025.0.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro==0.9.13->rl171==2025.0.0) (2.19.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.18.0->viser==0.2.6->rl171==2025.0.0) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.18.0->viser==0.2.6->rl171==2025.0.0) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->rl171==2025.0.0) (1.3.0)\n",
            "Collecting colorlog (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting manifold3d>=2.3.0 (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0)\n",
            "  Downloading manifold3d-3.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (3.4.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (4.25.1)\n",
            "Collecting svg.path (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0)\n",
            "  Downloading svg_path-7.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pycollada (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0)\n",
            "  Downloading pycollada-0.9.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (2.1.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (3.6.0)\n",
            "Collecting rtree (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0)\n",
            "  Downloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (0.28.1)\n",
            "Collecting embreex (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0)\n",
            "  Downloading embreex-2.17.7.post7-cp312-cp312-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting vhacdx (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0)\n",
            "  Downloading vhacdx-0.0.9-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting mapbox_earcut>=1.0.2 (from trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0)\n",
            "  Downloading mapbox_earcut-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco==3.2.4->rl171==2025.0.0) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco==3.2.4->rl171==2025.0.0) (3.23.0)\n",
            "Collecting cmeel-zlib (from cmeel-assimp<6,>=5.3.1->hpp-fcl<4,>=2.3.4->pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading cmeel_zlib-1.3.1-0-py3-none-manylinux_2_28_x86_64.whl.metadata (706 bytes)\n",
            "INFO: pip is looking at multiple versions of eigenpy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting eigenpy<4,>=3.1 (from hpp-fcl<4,>=2.3.4->pin==2.7.0->rl171==2025.0.0)\n",
            "  Downloading eigenpy-3.10.3-0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading eigenpy-3.10.1-1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading eigenpy-3.5.1-0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro==0.9.13->rl171==2025.0.0) (0.1.2)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.11.0->python-socketio>=5.0.2->flask_socketio==5.3.6->rl171==2025.0.0)\n",
            "  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (0.27.1)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.0.2->flask_socketio==5.3.6->rl171==2025.0.0)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->trimesh[easy]>=3.11.2->yourdfpy==0.0.56->rl171==2025.0.0) (1.3.1)\n",
            "Downloading flask-3.0.2-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.3/101.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_SocketIO-5.3.6-py3-none-any.whl (18 kB)\n",
            "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mink-0.0.13-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.7/914.7 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mujoco-3.2.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phoenix6-25.3.2-cp310-abi3-manylinux_2_35_x86_64.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pin-2.7.0-2-cp312-cp312-manylinux_2_28_x86_64.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycuber-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading redis-5.0.6-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.0/252.0 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruckig-0.12.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (891 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.0/892.0 kB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m128.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.13-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading viser-0.2.6-py3-none-any.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yourdfpy-0.0.56-py3-none-any.whl (22 kB)\n",
            "Downloading cmeel_boost-1.83.0-0-cp312-cp312-manylinux_2_28_x86_64.whl (34.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmeel_urdfdom-3.1.1.1-0-py3-none-manylinux_2_28_x86_64.whl (405 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpp_fcl-2.4.4-3-cp312-cp312-manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading plyfile-1.1.3-py3-none-any.whl (36 kB)\n",
            "Downloading python_socketio-5.14.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.9/78.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qpsolvers-4.8.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading quadprog-0.1.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (534 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m534.6/534.6 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading trimesh-4.9.0-py3-none-any.whl (736 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m736.5/736.5 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmeel-0.57.3-py3-none-any.whl (20 kB)\n",
            "Downloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.5/243.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
            "Downloading cmeel_assimp-5.4.3.1-0-py3-none-manylinux_2_28_x86_64.whl (14.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmeel_octomap-1.10.0-5-py3-none-manylinux_2_28_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmeel_qhull-8.0.2.1-1-py3-none-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading daqp-0.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (630 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.5/630.5 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eigenpy-3.5.1-0-cp312-cp312-manylinux_2_28_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading manifold3d-3.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mapbox_earcut-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_engineio-4.12.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmeel_console_bridge-1.0.2.3-0-py3-none-manylinux_2_28_x86_64.whl (24 kB)\n",
            "Downloading cmeel_tinyxml-2.6.2.3-0-py3-none-manylinux_2_28_x86_64.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading embreex-2.17.7.post7-cp312-cp312-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (17.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycollada-0.9.2-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.6/507.6 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading svg_path-7.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading vhacdx-0.0.9-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading cmeel_zlib-1.3.1-0-py3-none-manylinux_2_28_x86_64.whl (282 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: rl171, pyliblzfse\n",
            "  Building editable for rl171 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rl171: filename=rl171-2025.0.0-0.editable-py3-none-any.whl size=3121 sha256=f5d76265c1f2bd7513a90caab18602db07a1473e2fd8bbbf6c45f58ee2c5b06f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c_ca4389/wheels/40/b4/b9/c08a998bf87f53323d71d09c12e024d6dc79cf3ee020a0bb8e\n",
            "  Building wheel for pyliblzfse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyliblzfse: filename=pyliblzfse-0.4.1-cp312-cp312-linux_x86_64.whl size=88093 sha256=5d0c1e39bf12de983669b0728428f9806d16115bb0308156d70a7fddff58ed8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/bf/ee/8b734d20d3cc3e31b20be7c2aab7c407c9826dd03d87e1acf6\n",
            "Successfully built rl171 pyliblzfse\n",
            "Installing collected packages: pyliblzfse, pycuber, glfw, daqp, wsproto, svg.path, shtab, ruckig, rtree, redis, phoenix6, numpy, nodeenv, msgspec, colorlog, cmeel, bidict, vhacdx, trimesh, tensorboard, simple-websocket, quadprog, pycollada, plyfile, opencv-python, mapbox_earcut, manifold3d, gymnasium, flask, embreex, cmeel-zlib, cmeel-tinyxml, cmeel-qhull, cmeel-octomap, cmeel-console-bridge, cmeel-boost, tyro, qpsolvers, python-engineio, mujoco, matplotlib, eigenpy, cmeel-urdfdom, cmeel-assimp, python-socketio, hpp-fcl, yourdfpy, pin, mink, flask_socketio, viser, rl171\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.1\n",
            "    Uninstalling gymnasium-1.2.1:\n",
            "      Successfully uninstalled gymnasium-1.2.1\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 3.1.2\n",
            "    Uninstalling Flask-3.1.2:\n",
            "      Successfully uninstalled Flask-3.1.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires tensorboard~=2.19.0, but you have tensorboard 2.20.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bidict-0.23.1 cmeel-0.57.3 cmeel-assimp-5.4.3.1 cmeel-boost-1.83.0 cmeel-console-bridge-1.0.2.3 cmeel-octomap-1.10.0 cmeel-qhull-8.0.2.1 cmeel-tinyxml-2.6.2.3 cmeel-urdfdom-3.1.1.1 cmeel-zlib-1.3.1 colorlog-6.10.1 daqp-0.7.2 eigenpy-3.5.1 embreex-2.17.7.post7 flask-3.0.2 flask_socketio-5.3.6 glfw-2.10.0 gymnasium-0.29.1 hpp-fcl-2.4.4 manifold3d-3.2.1 mapbox_earcut-1.0.3 matplotlib-3.10.6 mink-0.0.13 msgspec-0.19.0 mujoco-3.2.4 nodeenv-1.9.1 numpy-1.26.4 opencv-python-4.9.0.80 phoenix6-25.3.2 pin-2.7.0 plyfile-1.1.3 pycollada-0.9.2 pycuber-0.2.2 pyliblzfse-0.4.1 python-engineio-4.12.3 python-socketio-5.14.2 qpsolvers-4.8.1 quadprog-0.1.13 redis-5.0.6 rl171-2025.0.0 rtree-1.4.1 ruckig-0.12.2 shtab-1.7.2 simple-websocket-1.1.0 svg.path-7.0 tensorboard-2.20.0 trimesh-4.9.0 tyro-0.9.13 vhacdx-0.0.9 viser-0.2.6 wsproto-1.2.0 yourdfpy-0.0.56\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "e713b5b5f5a44196a38f18d5cafa63b1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!gdown 1_p4T016W1_YUGU8S1FyarJPmUxiSsyZM\n",
        "!unzip /content/rl171-ex1.zip -d /content/rl171-ex1/\n",
        "\n",
        "# Install the code\n",
        "!pip install -e /content/rl171-ex1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation Part 2\n",
        "\n",
        "After restarting the session, run the following cell to install the remaining requirements. No further restart is necessary."
      ],
      "metadata": {
        "id": "ImoMstr8lmQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Environments for the course\n",
        "\n",
        "# Rendering for GColab\n",
        "# from: https://colab.research.google.com/github/google-deepmind/mujoco/blob/main/python/tutorial.ipynb#scrollTo=Xqo7pyX-n72M\n",
        "# Set up GPU rendering.\n",
        "from google.colab import files\n",
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.')\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "# Check if installation was succesful.\n",
        "try:\n",
        "  print('Checking that the installation succeeded:')\n",
        "  import mujoco\n",
        "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
        "except Exception as e:\n",
        "  raise e from RuntimeError(\n",
        "      'Something went wrong during installation. Check the shell output above '\n",
        "      'for more information.\\n'\n",
        "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
        "\n",
        "print('Installation successful.')\n",
        "\n",
        "# Other imports and helper functions\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "# Graphics and plotting.\n",
        "print('Installing mediapy:')\n",
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "!pip install -q mediapy\n",
        "import mediapy as media\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# More legible printing from numpy.\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "# for CleanRL\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import gymnasium as gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import tyro\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from typing import Callable, Any, NamedTuple\n",
        "from gymnasium import spaces\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "\n",
        "# For CleanRL\n",
        "from __future__ import annotations\n",
        "\n",
        "import warnings\n",
        "from abc import ABC, abstractmethod\n",
        "from collections.abc import Generator\n",
        "import cv2\n",
        "import base64\n",
        "import imageio\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "\n",
        "## Not important - CLEAN RL UTILS from https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl_utils/buffers.py ##\n",
        "def get_obs_shape(\n",
        "    observation_space: spaces.Space,\n",
        ") -> tuple[int, ...] | dict[str, tuple[int, ...]]:\n",
        "    \"\"\"\n",
        "    Get the shape of the observation (useful for the buffers).\n",
        "\n",
        "    :param observation_space:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if isinstance(observation_space, spaces.Box):\n",
        "        return observation_space.shape\n",
        "    elif isinstance(observation_space, spaces.Discrete):\n",
        "        # Observation is an int\n",
        "        return (1,)\n",
        "    elif isinstance(observation_space, spaces.MultiDiscrete):\n",
        "        # Number of discrete features\n",
        "        return (int(len(observation_space.nvec)),)\n",
        "    elif isinstance(observation_space, spaces.MultiBinary):\n",
        "        # Number of binary features\n",
        "        return observation_space.shape\n",
        "    elif isinstance(observation_space, spaces.Dict):\n",
        "        return {key: get_obs_shape(subspace) for (key, subspace) in observation_space.spaces.items()}  # type: ignore[misc]\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(f\"{observation_space} observation space is not supported\")\n",
        "\n",
        "def get_action_dim(action_space: spaces.Space) -> int:\n",
        "    \"\"\"\n",
        "    Get the dimension of the action space.\n",
        "\n",
        "    :param action_space:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if isinstance(action_space, spaces.Box):\n",
        "        return int(np.prod(action_space.shape))\n",
        "    elif isinstance(action_space, spaces.Discrete):\n",
        "        # Action is an int\n",
        "        return 1\n",
        "    elif isinstance(action_space, spaces.MultiDiscrete):\n",
        "        # Number of discrete actions\n",
        "        return int(len(action_space.nvec))\n",
        "    elif isinstance(action_space, spaces.MultiBinary):\n",
        "        # Number of binary actions\n",
        "        assert isinstance(\n",
        "            action_space.n, int\n",
        "        ), f\"Multi-dimensional MultiBinary({action_space.n}) action space is not supported. You can flatten it instead.\"\n",
        "        return int(action_space.n)\n",
        "    else:\n",
        "        raise NotImplementedError(f\"{action_space} action space is not supported\")\n",
        "\n",
        "def get_device(device: torch.device | str = \"auto\") -> torch.device:\n",
        "    \"\"\"\n",
        "    Retrieve PyTorch device.\n",
        "    It checks that the requested device is available first.\n",
        "    For now, it supports only cpu and cuda.\n",
        "    By default, it tries to use the gpu.\n",
        "\n",
        "    :param device: One for 'auto', 'cuda', 'cpu'\n",
        "    :return: Supported Pytorch device\n",
        "    \"\"\"\n",
        "    # Cuda by default\n",
        "    if device == \"auto\":\n",
        "        device = \"cuda\"\n",
        "    # Force conversion to torch.device\n",
        "    device = torch.device(device)\n",
        "\n",
        "    # Cuda not available\n",
        "    if device.type == torch.device(\"cuda\").type and not torch.cuda.is_available():\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "    return device\n",
        "\n",
        "try:\n",
        "    # Check memory used by replay buffer when possible\n",
        "    import psutil\n",
        "except ImportError:\n",
        "    psutil = None\n",
        "\n",
        "\n",
        "def add_text_to_frame(frame: np.ndarray, text: str) -> np.ndarray:\n",
        "    \"\"\"Adds text to a single frame (expects an RGB numpy array).\"\"\"\n",
        "    pil_img = Image.fromarray(frame)\n",
        "    pil_img = pil_img.resize((640, 480))\n",
        "    pil_img = pil_img.convert(\"RGBA\")\n",
        "    draw = ImageDraw.Draw(pil_img)\n",
        "\n",
        "    try:\n",
        "        font_path = fm.findfont(\"DejaVu Sans\")\n",
        "        font = ImageFont.truetype(font_path, size=30)\n",
        "    except Exception:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    # Add text with a semi-transparent background for better visibility\n",
        "    text_position = (15, 15)\n",
        "    text_bbox = draw.textbbox(text_position, text, font=font)\n",
        "    # Add a small padding\n",
        "    bg_bbox = (text_bbox[0]-5, text_bbox[1]-5, text_bbox[2]+5, text_bbox[3]+5)\n",
        "    draw.rectangle(bg_bbox, fill=(0, 0, 0, 128)) # Black with 50% opacity\n",
        "    draw.text(text_position, text, font=font, fill=(255, 255, 255)) # White text\n",
        "\n",
        "    return np.array(pil_img)\n",
        "\n",
        "def show_video(frames: list, fps: int = 20):\n",
        "    \"\"\"Shows a list of RGB frames as an HTML5 video\"\"\"\n",
        "    if not frames:\n",
        "        print(\"No frames to display.\")\n",
        "        return\n",
        "\n",
        "    # Use imageio to write the frames to a buffer in memory\n",
        "    # The '<bytes>' URI tells imageio to output to a byte string\n",
        "    video_bytes = imageio.mimwrite('<bytes>', frames, format='mp4', fps=fps)\n",
        "\n",
        "    # Encode the video bytes for HTML display\n",
        "    video_b64 = base64.b64encode(video_bytes).decode()\n",
        "    html_str = f'<video controls autoplay loop><source src=\"data:video/mp4;base64,{video_b64}\" type=\"video/mp4\"></video>'\n",
        "    display(HTML(html_str))\n",
        "\n",
        "FPS = 15 # frames per second\n",
        "\n"
      ],
      "metadata": {
        "id": "bWUcXLivy28p",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "0c528c0f-1b64-47d0-d6c5-7dc106cc4ab1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting environment variable to use GPU rendering:\n",
            "env: MUJOCO_GL=egl\n",
            "Checking that the installation succeeded:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mujoco'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: Something went wrong during installation. Check the shell output above for more information.\nIf using a hosted Colab runtime, make sure you enable GPU acceleration by going to the Runtime menu and selecting \"Choose runtime type\".",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3999569994.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mmujoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMjModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_xml_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<mujoco/>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   raise e from RuntimeError(\n\u001b[0m\u001b[1;32m     42\u001b[0m       \u001b[0;34m'Something went wrong during installation. Check the shell output above '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0;34m'for more information.\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3999569994.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Checking that the installation succeeded:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mmujoco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0mmujoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMjModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_xml_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<mujoco/>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mujoco'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0CF6Gvkt_Cw"
      },
      "source": [
        "# Cube Environment\n",
        "\n",
        "We will begin by defining and loading a simple environment: a virtual [Rubik's cube](https://en.wikipedia.org/wiki/Rubik's_Cube). The goal is to arrange the cube so that each of its six faces has a single colour. Your objective is to train a DQN agent to solve a scrambled cube.\n",
        "\n",
        "The image below shows three sides of a solved cube.\n",
        "\n",
        "![cube.png](data:image/png;base64,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)\n",
        "\n",
        "------\n",
        "## Observations\n",
        "\n",
        "The environment's observation is a one-dimensional vector of 54 integers that numerically represents the cube's state. The vector's 54 entries correspond to the 9 squares on each of the 6 faces (9 squares * 6 faces = 54). Each integer represents a specific color, as defined by the following mapping:\n",
        "\n",
        "| Color | Value |\n",
        "| :--- | :--- |\n",
        "| `white` | 0 |\n",
        "| `yellow`| 1 |\n",
        "| `green` | 2 |\n",
        "| `blue` | 3 |\n",
        "| `red` | 4 |\n",
        "| `orange`| 5 |\n",
        "\n",
        "To ensure consistency, the faces are always serialized in the same sequence: Up, Left, Front, Right, Back, and Down.\n",
        "\n",
        "---\n",
        "\n",
        "## Actions\n",
        "\n",
        "The agent can perform 12 distinct actions to manipulate the cube. These actions correspond to the standard notation for Rubik's Cube moves, where each letter represents a face and an apostrophe (`'`) indicates a counter-clockwise turn.\n",
        "\n",
        "* **L, L'**: Turn the **Left** face clockwise or counter-clockwise.\n",
        "* **R, R'**: Turn the **Right** face clockwise or counter-clockwise.\n",
        "* **F, F'**: Turn the **Front** face clockwise or counter-clockwise.\n",
        "* **B, B'**: Turn the **Back** face clockwise or counter-clockwise.\n",
        "* **D, D'**: Turn the **Down** face clockwise or counter-clockwise.\n",
        "* **U, U'**: Turn the **Up** face clockwise or counter-clockwise.\n",
        "\n",
        "Further details on this notation are available at https://ruwix.com/the-rubiks-cube/notation/.\n",
        "\n",
        "---\n",
        "\n",
        "## Reward\n",
        "\n",
        "The reward function is structured to guide the agent toward solving the cube efficiently. The reward at each step is the sum of three components:\n",
        "\n",
        "    * +5 points for each new face that becomes solved.\n",
        "    * -5 points for each previously solved face that is un-solved.\n",
        "    * +50 points are awarded at the moment the entire cube is solved.\n",
        "    * -0.1 points for every move. This incentivizes the agent to find the most efficient solution."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code in the next cell provides a basic demonstration. The code start with a solved cube, takes two random actions to show how the state changes. Feel free to play around with the cube to get used to the environment!"
      ],
      "metadata": {
        "id": "fvwF3TQzx1Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Demo\n",
        "from rl171.mujoco_env_cube_only import CubeGymEnv\n",
        "\n",
        "# Define the 12 possible face rotations using standard Rubik's Cube notation\n",
        "# (e.g., \"L\" is a clockwise turn of the left face).\n",
        "# See: https://ruwix.com/the-rubiks-cube/notation/\n",
        "PYCUBER_ACTIONS = [\"L\", \"L'\", \"R\", \"R'\", \"F\", \"F'\", \"B\", \"B'\", \"D\", \"D'\", \"U\", \"U'\"]\n",
        "\n",
        "# For this demo, we take two random questions to see how the cube changes.\n",
        "demo_actions = [6, 2, 3, 7] # indices of the action we want to take, as in PYCUBER_ACTIONS\n",
        "nr_timesteps = len(demo_actions)\n",
        "\n",
        "# The environment is configured with the following key parameters:\n",
        "\n",
        "# 'render_mode': Controls how the cube is visualized.\n",
        "#   - 'rgb_array': Returns an RGB image of the cube's state. This is useful\n",
        "#     for saving frames to create a video of the agent's solution.\n",
        "#   - 'human': Opens an interactive window to display the cube. This is ideal\n",
        "#     for live observation when running the script locally (requires\n",
        "#     running the script with 'mjpython').\n",
        "#\n",
        "#   **NOTE**: The 'demo' mode, which animates face movements, used below should NOT\n",
        "#   be used for training. It relies on interpolation and is unstable for\n",
        "#   complex move sequences.\n",
        "\n",
        "# 'max_time_steps': Sets the maximum number of moves the agent is allowed\n",
        "#   per episode. The episode ends if this limit is reached (`truncated` = True).\n",
        "\n",
        "# 'num_scramble_steps': Defines the number of random moves applied to a\n",
        "#   solved cube to create its initial, scrambled starting position.\n",
        "env = CubeGymEnv(render_mode=\"demo\", max_time_steps=100, num_scramble_steps=0)\n",
        "\n",
        "truncated = False\n",
        "terminated = False\n",
        "\n",
        "frames = [] # for rendering (video)\n",
        "obs, _ = env.reset() # bring the cube to its initial position\n",
        "\n",
        "### for rendering (video) ###\n",
        "initial_frames = env.render()\n",
        "processed_initial_frame = add_text_to_frame(initial_frames[0], \"Initial State\")\n",
        "# Duplicate the initial frame to hold it for ~1 seconds\n",
        "frames.extend([processed_initial_frame] * FPS)\n",
        "######\n",
        "\n",
        "for t in range(nr_timesteps):\n",
        "\n",
        "  action = demo_actions[t]\n",
        "\n",
        "  # Simulate the action on the cube.\n",
        "  obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "  ### for rendering (video) ###\n",
        "  animation_frames = env.render()\n",
        "  animation_frames = [\n",
        "      add_text_to_frame(frame, f\"Action: {PYCUBER_ACTIONS[action]}\") for frame in animation_frames\n",
        "  ]\n",
        "  frames.extend(animation_frames)\n",
        "  ######\n",
        "\n",
        "  if truncated or terminated:\n",
        "    ### for rendering (video) ###\n",
        "    end_frame = add_text_to_frame(animation_frames[-1], \"Episode End / Reset\")\n",
        "    frames.extend([end_frame] * FPS)\n",
        "    ######\n",
        "\n",
        "    obs, info = env.reset()\n",
        "\n",
        "### for rendering (video) ###\n",
        "show_video(frames, fps=FPS)\n",
        "###\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "dFdRGM4VpqsR",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The video above should be about 7 seconds long. It shows the cube starting in its solved state, then applying two random actions and immediately undoing them to return the cube to its solved position."
      ],
      "metadata": {
        "id": "d_P-cAvDsXbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXERCISES: FILL THE GAPS\n",
        "\n",
        "The code cells below are incomplete. Your task is to fill in the missing lines (marked with a `TODO`) to complete the exercise. ❗ Familiarise yourself with the rest of the code. It may come in handy❗\n",
        "\n",
        "The exercise is heavily based on code by [CleanRL](https://docs.cleanrl.dev/). While checking the source code can give you most of the answers, please do not simply copy and paste, as it would defeat the purpose of the exercise. The document is designed to help you start thinking about the concepts we have covered in class. Looking up the solution and copying it will not help you prepare for our in-class discussion or future assessment."
      ],
      "metadata": {
        "id": "GJgSlJmwennX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replay buffers\n",
        "\n",
        "The RL, an agent often benefits from remembering its past experiences. A replay buffer is a data structure storing these experiences so the agent can learn from them later.\n",
        "\n",
        "**Why is Experience Replay Useful in DQN?**\n",
        "\n",
        "Think back to our lecture. We discussed two key reasons why experience replay is crucial for training a stable and effective DQN agent. Can you recall them?\n",
        "1) We can shuffle the previously sampled data to break short term correlations in the data. This prevents the agent from learning short term patterns and helps the agent to generalize better.\n",
        "2) The agent is able to learn from past policies which leads to a better data distribution. (Not only learning from the current policy)\n",
        "\n",
        "The cell below contains the basic structure of a Replay Buffer, based on the implemention from CleanRL. If you have not worked with replay buffers before, please take a look at the code. Otherwise, feel free to jump to the next cell!\n",
        "\n",
        "There is nothing for you to complete in the following cell. Ensure you understand the basic structure of a Replay Buffer. It may help later on!\n"
      ],
      "metadata": {
        "id": "vwSWbHDakKs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBufferSamples(NamedTuple):\n",
        "    observations: torch.Tensor\n",
        "    actions: torch.Tensor\n",
        "    next_observations: torch.Tensor\n",
        "    dones: torch.Tensor\n",
        "    rewards: torch.Tensor\n",
        "\n",
        "class BaseBuffer(ABC):\n",
        "    \"\"\"\n",
        "    Base class that represent a buffer (rollout or replay)\n",
        "\n",
        "    :param buffer_size: Max number of element in the buffer\n",
        "    :param observation_space: Observation space\n",
        "    :param action_space: Action space\n",
        "    :param device: PyTorch device\n",
        "        to which the values will be converted\n",
        "    :param n_envs: Number of parallel environments\n",
        "    \"\"\"\n",
        "\n",
        "    observation_space: spaces.Space\n",
        "    obs_shape: tuple[int, ...]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        buffer_size: int,\n",
        "        observation_space: spaces.Space,\n",
        "        action_space: spaces.Space,\n",
        "        device: torch.device | str = \"auto\",\n",
        "        n_envs: int = 1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.buffer_size = buffer_size\n",
        "        self.observation_space = observation_space\n",
        "        self.action_space = action_space\n",
        "        self.obs_shape = get_obs_shape(observation_space)  # type: ignore[assignment]\n",
        "\n",
        "        self.action_dim = get_action_dim(action_space)\n",
        "        self.pos = 0\n",
        "        self.full = False\n",
        "        self.device = get_device(device)\n",
        "        self.n_envs = n_envs\n",
        "\n",
        "    @staticmethod\n",
        "    def swap_and_flatten(arr: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Swap and then flatten axes 0 (buffer_size) and 1 (n_envs)\n",
        "        to convert shape from [n_steps, n_envs, ...] (when ... is the shape of the features)\n",
        "        to [n_steps * n_envs, ...] (which maintain the order)\n",
        "\n",
        "        :param arr:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        shape = arr.shape\n",
        "        if len(shape) < 3:\n",
        "            shape = (*shape, 1)\n",
        "        return arr.swapaxes(0, 1).reshape(shape[0] * shape[1], *shape[2:])\n",
        "\n",
        "    def size(self) -> int:\n",
        "        \"\"\"\n",
        "        :return: The current size of the buffer\n",
        "        \"\"\"\n",
        "        if self.full:\n",
        "            return self.buffer_size\n",
        "        return self.pos\n",
        "\n",
        "    def add(self, *args, **kwargs) -> None:\n",
        "        \"\"\"\n",
        "        Add elements to the buffer.\n",
        "        \"\"\"\n",
        "        # Ignore NotImplementedError. This is an abstract class, and this\n",
        "        # exception is raised only if a class inheriting from BaseBuffer\n",
        "        # doesn't implement this function.\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def extend(self, *args, **kwargs) -> None:\n",
        "        \"\"\"\n",
        "        Add a new batch of transitions to the buffer\n",
        "        \"\"\"\n",
        "        # Do a for loop along the batch axis\n",
        "        for data in zip(*args):\n",
        "            self.add(*data)\n",
        "\n",
        "    def reset(self) -> None:\n",
        "        \"\"\"\n",
        "        Reset the buffer.\n",
        "        \"\"\"\n",
        "        self.pos = 0\n",
        "        self.full = False\n",
        "\n",
        "    def sample(self, batch_size: int):\n",
        "        \"\"\"\n",
        "        :param batch_size: Number of element to sample\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        upper_bound = self.buffer_size if self.full else self.pos\n",
        "        batch_inds = np.random.randint(0, upper_bound, size=batch_size)\n",
        "        return self._get_samples(batch_inds)\n",
        "\n",
        "    @abstractmethod\n",
        "    def _get_samples(self, batch_inds: np.ndarray) -> ReplayBufferSamples | RolloutBufferSamples:\n",
        "        \"\"\"\n",
        "        :param batch_inds:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def to_torch(self, array: np.ndarray, copy: bool = True) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Convert a numpy array to a PyTorch tensor.\n",
        "        Note: it copies the data by default\n",
        "\n",
        "        :param array:\n",
        "        :param copy: Whether to copy or not the data (may be useful to avoid changing things\n",
        "            by reference). This argument is inoperative if the device is not the CPU.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            return torch.tensor(array, device=self.device)\n",
        "        return torch.as_tensor(array, device=self.device)"
      ],
      "metadata": {
        "id": "5TI1UMK5kiny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the general skeleton is provided by BaseBuffer, there are many different ways an agent could store and retrieve transitions. We could use strategies such as First in, first out (FIFO), uniform random sampling, or others! What does the `ReplayBuffer` below use?"
      ],
      "metadata": {
        "id": "qOmjT20rtOso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer(BaseBuffer):\n",
        "    \"\"\"\n",
        "    Replay buffer used in off-policy algorithms like SAC/TD3.\n",
        "\n",
        "    :param buffer_size: Max number of element in the buffer\n",
        "    :param observation_space: Observation space\n",
        "    :param action_space: Action space\n",
        "    :param device: PyTorch device\n",
        "    :param n_envs: Number of parallel environments\n",
        "    :param optimize_memory_usage: Enable a memory efficient variant\n",
        "        of the replay buffer which reduces by almost a factor two the memory used,\n",
        "        at a cost of more complexity.\n",
        "        See https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195\n",
        "        and https://github.com/DLR-RM/stable-baselines3/pull/28#issuecomment-637559274\n",
        "        Cannot be used in combination with handle_timeout_termination.\n",
        "    :param handle_timeout_termination: Handle timeout termination (due to timelimit)\n",
        "        separately and treat the task as infinite horizon task.\n",
        "        https://github.com/DLR-RM/stable-baselines3/issues/284\n",
        "    \"\"\"\n",
        "\n",
        "    observations: np.ndarray\n",
        "    next_observations: np.ndarray\n",
        "    actions: np.ndarray\n",
        "    rewards: np.ndarray\n",
        "    dones: np.ndarray\n",
        "    timeouts: np.ndarray\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        buffer_size: int,\n",
        "        observation_space: spaces.Space,\n",
        "        action_space: spaces.Space,\n",
        "        device: torch.device | str = \"auto\",\n",
        "        n_envs: int = 1,\n",
        "        optimize_memory_usage: bool = False,\n",
        "        handle_timeout_termination: bool = True,\n",
        "    ):\n",
        "        super().__init__(buffer_size, observation_space, action_space, device, n_envs=n_envs)\n",
        "\n",
        "        # Adjust buffer size\n",
        "        self.buffer_size = max(buffer_size // n_envs, 1)\n",
        "\n",
        "        # Check that the replay buffer can fit into the memory\n",
        "        if psutil is not None:\n",
        "            mem_available = psutil.virtual_memory().available\n",
        "\n",
        "        # there is a bug if both optimize_memory_usage and handle_timeout_termination are true\n",
        "        # see https://github.com/DLR-RM/stable-baselines3/issues/934\n",
        "        if optimize_memory_usage and handle_timeout_termination:\n",
        "            raise ValueError(\n",
        "                \"ReplayBuffer does not support optimize_memory_usage = True \"\n",
        "                \"and handle_timeout_termination = True simultaneously.\"\n",
        "            )\n",
        "        self.optimize_memory_usage = optimize_memory_usage\n",
        "\n",
        "        self.observations = np.zeros((self.buffer_size, self.n_envs, *self.obs_shape), dtype=observation_space.dtype)\n",
        "\n",
        "        if not optimize_memory_usage:\n",
        "            # When optimizing memory, `observations` contains also the next observation\n",
        "            self.next_observations = np.zeros((self.buffer_size, self.n_envs, *self.obs_shape), dtype=observation_space.dtype)\n",
        "\n",
        "        self.actions = np.zeros(\n",
        "            (self.buffer_size, self.n_envs, self.action_dim), dtype=self._maybe_cast_dtype(action_space.dtype)\n",
        "        )\n",
        "\n",
        "        self.rewards = np.zeros((self.buffer_size, self.n_envs), dtype=np.float32)\n",
        "        self.dones = np.zeros((self.buffer_size, self.n_envs), dtype=np.float32)\n",
        "        # Handle timeouts termination properly if needed\n",
        "        # see https://github.com/DLR-RM/stable-baselines3/issues/284\n",
        "        self.handle_timeout_termination = handle_timeout_termination\n",
        "        self.timeouts = np.zeros((self.buffer_size, self.n_envs), dtype=np.float32)\n",
        "\n",
        "        if psutil is not None:\n",
        "            total_memory_usage: float = (\n",
        "                self.observations.nbytes + self.actions.nbytes + self.rewards.nbytes + self.dones.nbytes\n",
        "            )\n",
        "\n",
        "            if not optimize_memory_usage:\n",
        "                total_memory_usage += self.next_observations.nbytes\n",
        "\n",
        "            if total_memory_usage > mem_available:\n",
        "                # Convert to GB\n",
        "                total_memory_usage /= 1e9\n",
        "                mem_available /= 1e9\n",
        "                warnings.warn(\n",
        "                    \"This system does not have apparently enough memory to store the complete \"\n",
        "                    f\"replay buffer {total_memory_usage:.2f}GB > {mem_available:.2f}GB\"\n",
        "                )\n",
        "\n",
        "    def add(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        next_obs: np.ndarray,\n",
        "        action: np.ndarray,\n",
        "        reward: np.ndarray,\n",
        "        done: np.ndarray,\n",
        "        infos: list[dict[str, Any]],\n",
        "    ) -> None:\n",
        "        # Reshape needed when using multiple envs with discrete observations\n",
        "        # as numpy cannot broadcast (n_discrete,) to (n_discrete, 1)\n",
        "        if isinstance(self.observation_space, spaces.Discrete):\n",
        "            obs = obs.reshape((self.n_envs, *self.obs_shape))\n",
        "            next_obs = next_obs.reshape((self.n_envs, *self.obs_shape))\n",
        "\n",
        "        # Reshape to handle multi-dim and discrete action spaces, see GH #970 #1392\n",
        "        action = action.reshape((self.n_envs, self.action_dim))\n",
        "\n",
        "        # Copy to avoid modification by reference\n",
        "        self.observations[self.pos] = np.array(obs)\n",
        "\n",
        "        if self.optimize_memory_usage:\n",
        "            self.observations[(self.pos + 1) % self.buffer_size] = np.array(next_obs)\n",
        "        else:\n",
        "            self.next_observations[self.pos] = np.array(next_obs)\n",
        "\n",
        "        self.actions[self.pos] = np.array(action)\n",
        "        self.rewards[self.pos] = np.array(reward)\n",
        "        self.dones[self.pos] = np.array(done)\n",
        "\n",
        "        if self.handle_timeout_termination:\n",
        "            self.timeouts[self.pos] = np.array([info.get(\"TimeLimit.truncated\", False) for info in infos])\n",
        "\n",
        "        self.pos += 1\n",
        "        if self.pos == self.buffer_size:\n",
        "            self.full = True\n",
        "            self.pos = 0\n",
        "\n",
        "    def sample(self, batch_size: int) -> ReplayBufferSamples:\n",
        "        \"\"\"\n",
        "        Sample elements from the replay buffer.\n",
        "        Custom sampling when using memory efficient variant,\n",
        "        as we should not sample the element with index `self.pos`\n",
        "        See https://github.com/DLR-RM/stable-baselines3/pull/28#issuecomment-637559274\n",
        "\n",
        "        :param batch_size: Number of element to sample\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if not self.optimize_memory_usage:\n",
        "            return super().sample(batch_size=batch_size)\n",
        "        # Do not sample the element with index `self.pos` as the transitions is invalid\n",
        "        # (we use only one array to store `obs` and `next_obs`)\n",
        "        if self.full:\n",
        "            batch_inds = (np.random.randint(1, self.buffer_size, size=batch_size) + self.pos) % self.buffer_size\n",
        "        else:\n",
        "            batch_inds = np.random.randint(0, self.pos, size=batch_size)\n",
        "        return self._get_samples(batch_inds)\n",
        "\n",
        "    def _get_samples(self, batch_inds: np.ndarray) -> ReplayBufferSamples:\n",
        "        # Sample randomly the env idx\n",
        "        env_indices = np.random.randint(0, high=self.n_envs, size=(len(batch_inds),))\n",
        "\n",
        "        if self.optimize_memory_usage:\n",
        "            next_obs = self.observations[(batch_inds + 1) % self.buffer_size, env_indices, :]\n",
        "        else:\n",
        "            next_obs = self.next_observations[batch_inds, env_indices, :]\n",
        "\n",
        "        data = (\n",
        "            self.observations[batch_inds, env_indices, :],\n",
        "            self.actions[batch_inds, env_indices, :],\n",
        "            next_obs,\n",
        "            # Only use dones that are not due to timeouts\n",
        "            # deactivated by default (timeouts is initialized as an array of False)\n",
        "            (self.dones[batch_inds, env_indices] * (1 - self.timeouts[batch_inds, env_indices])).reshape(-1, 1),\n",
        "            self.rewards[batch_inds, env_indices].reshape(-1, 1),\n",
        "        )\n",
        "        return ReplayBufferSamples(*tuple(map(self.to_torch, data)))\n",
        "\n",
        "    @staticmethod\n",
        "    def _maybe_cast_dtype(dtype: np.typing.DTypeLike) -> np.typing.DTypeLike:\n",
        "        \"\"\"\n",
        "        Cast `np.float64` action datatype to `np.float32`,\n",
        "        keep the others dtype unchanged.\n",
        "        See GH#1572 for more information.\n",
        "\n",
        "        :param dtype: The original action space dtype\n",
        "        :return: ``np.float32`` if the dtype was float64,\n",
        "            the original dtype otherwise.\n",
        "        \"\"\"\n",
        "        if dtype == np.float64:\n",
        "            return np.float32\n",
        "        return dtype"
      ],
      "metadata": {
        "id": "zu6x4AULkM7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DQN: Setup\n",
        "\n",
        "We first define some hyperparameters for the algorithm.\n",
        "\n"
      ],
      "metadata": {
        "id": "9dmMO-lJfbbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# docs and experiment results can be found at https://docs.cleanrl.dev/rl-algorithms/dqn/#dqnpy\n",
        "\n",
        "@dataclass\n",
        "class Args:\n",
        "    # Feel free to modify these parameters\n",
        "    num_scramble_steps: int = 1\n",
        "    \"\"\"number of initial scramble steps for the cube environment\"\"\"\n",
        "    max_time_steps: int = 5\n",
        "    \"\"\"max time steps per episode\"\"\"\n",
        "    total_timesteps: int = 50000\n",
        "    \"\"\"total timesteps of the experiments\"\"\"\n",
        "    learning_rate: float = 2.5e-4\n",
        "    \"\"\"the learning rate of the optimizer\"\"\"\n",
        "    seed: int = 1\n",
        "    \"\"\"seed of the experiment\"\"\"\n",
        "    buffer_size: int = 10000\n",
        "    \"\"\"the replay memory buffer size\"\"\"\n",
        "    batch_size: int = 128\n",
        "    \"\"\"the batch size of sample from the reply memory\"\"\"\n",
        "    start_e: float = 1\n",
        "    \"\"\"the starting epsilon for exploration\"\"\"\n",
        "    end_e: float = 0.05\n",
        "    \"\"\"the ending epsilon for exploration\"\"\"\n",
        "    exploration_fraction: float = 0.5\n",
        "    \"\"\"the fraction of `total-timesteps` it takes from start-e to go end-e\"\"\"\n",
        "    learning_starts: int = 10000\n",
        "    \"\"\"timestep to start learning\"\"\"\n",
        "    train_frequency: int = 10\n",
        "    \"\"\"the frequency of training\"\"\"\n",
        "    tau: float = 1.0\n",
        "    \"\"\"the target network update rate\"\"\"\n",
        "    target_network_frequency: int = 500\n",
        "    \"\"\"the timesteps it takes to update the target network\"\"\"\n",
        "\n",
        "    # You should not need to change these\n",
        "    exp_name: str = \"rl171_ex1\"\n",
        "    torch_deterministic: bool = True\n",
        "    \"\"\"if toggled, `torch.backends.cudnn.deterministic=False`\"\"\"\n",
        "    cuda: bool = True\n",
        "    \"\"\"if toggled, cuda will be enabled by default\"\"\"\n",
        "    num_envs: int = 1\n",
        "    \"\"\"the number of parallel game environments\"\"\"\n",
        "    gamma: float = 0.99\n",
        "    \"\"\"the discount factor gamma\"\"\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nDg8GEDpfa2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epsilon-greedy is a fundamental strategy in reinforcement learning designed to solve the exploration-exploitation dilemma.\n",
        "\n",
        "An agent in a new environment must decide whether to exploit its current knowledge by choosing the action it believes is best, or to explore by trying a random action in the hopes of discovering an even better reward.\n",
        "\n",
        "The epsilon ($\\epsilon$) parameter represents the probability that the agent will choose to explore.\n",
        "- With a probability of $1 - \\epsilon$, the agent acts greedily, choosing the action with the highest estimated Q-value.\n",
        "- With a probability of $\\epsilon$, the agent ignores its knowledge and chooses a completely random action.\n",
        "\n",
        "This simple rule ensures the agent continues to learn about its environment while also making use of what it already knows. To make learning more effective, the balance between exploration and exploitation should change over time. Initially, when the agent knows little, exploration is more important. As it gains experience, it should increasingly rely on its knowledge. This is achieved through a technique called epsilon decay, where the value of $\\epsilon$ is gradually reduced over the training period. For this course, we will use a linear decay schedule, which is implemented in the `linear_schedule` function. While there are exist other decay strategies, the course will only cover the linear one.\n",
        "\n",
        "The agent's knowledge is learned and stored in a neural network. The code below defines the architecture for our Q-network, which is responsible for approximating the Q-values (the expected rewards) for every possible action in a given state. The $\\epsilon$-greedy policy uses these Q-values to make its decisions whenever it chooses to exploit."
      ],
      "metadata": {
        "id": "oXWNlAvFR_2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ALGO LOGIC: initialize agent here:\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, env):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(np.array(env.single_observation_space.shape).prod(), 120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, env.single_action_space.n),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
        "    slope = (end_e - start_e) / duration\n",
        "    return max(slope * t + start_e, end_e)\n"
      ],
      "metadata": {
        "id": "JBFDIcQ0jmHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DQN: Training\n",
        "\n",
        "It will take a few minutes for the agent to train."
      ],
      "metadata": {
        "id": "idByy1AeHdVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_env(max_time_steps, num_scramble_steps, seed):\n",
        "    \"\"\"\n",
        "    Create environment wrapper function\n",
        "    Args:\n",
        "        max_time_steps (int): max time steps per episode\n",
        "        num_scramble_steps (int): how many random moves to scramble the cube at the start of each episode\n",
        "        seed (int): seed of the experiment\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def thunk():\n",
        "        env = CubeGymEnv(render_mode=\"rgb_array\",\n",
        "                                max_time_steps=max_time_steps,\n",
        "                                num_scramble_steps=num_scramble_steps)\n",
        "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "        env.action_space.seed(seed)\n",
        "\n",
        "        return env\n",
        "\n",
        "    return thunk"
      ],
      "metadata": {
        "id": "g2SKHL1nHgQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = Args()\n",
        "assert args.num_envs == 1, \"vectorized envs are not supported at the moment\"\n",
        "run_name = f\"{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
        "\n",
        "# Logger -- more details are in the \"Evaluation\" section below\n",
        "writer = SummaryWriter(f\"runs/{run_name}\")\n",
        "writer.add_text(\n",
        "    \"hyperparameters\",\n",
        "    \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
        ")\n",
        "\n",
        "# TRY NOT TO MODIFY: seeding\n",
        "random.seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "torch.backends.cudnn.deterministic = args.torch_deterministic\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
        "\n",
        "# env setup\n",
        "envs = gym.vector.SyncVectorEnv(\n",
        "    [make_env(max_time_steps=args.max_time_steps, seed=args.seed + i,\n",
        "              num_scramble_steps=args.num_scramble_steps) for i in range(args.num_envs)]\n",
        ")\n",
        "assert isinstance(envs.single_action_space, gym.spaces.Discrete), \"only discrete action space is supported\"\n",
        "\n",
        "q_network = QNetwork(envs).to(device)\n",
        "optimizer = optim.Adam(q_network.parameters(), lr=args.learning_rate)\n",
        "target_network = QNetwork(envs).to(device)\n",
        "target_network.load_state_dict(q_network.state_dict())\n",
        "\n",
        "rb = ReplayBuffer(\n",
        "    args.buffer_size,\n",
        "    envs.single_observation_space,\n",
        "    envs.single_action_space,\n",
        "    device,\n",
        "    handle_timeout_termination=False,\n",
        ")\n",
        "start_time = time.time()\n",
        "\n",
        "# TRY NOT TO MODIFY: start the game\n",
        "obs, _ = envs.reset(seed=args.seed)\n",
        "for global_step in range(args.total_timesteps):\n",
        "    # ALGO LOGIC: put action logic here\n",
        "    epsilon = linear_schedule(args.start_e, args.end_e, args.exploration_fraction * args.total_timesteps, global_step)\n",
        "    if random.random() < epsilon:\n",
        "      # TODO-Done: take a random action. Make sure you understand why/when this line will run.\n",
        "      # Since the code uses vectorised environments, we provide the main code. You\n",
        "      # just need to sample the action of a specific environment (i.e., change\n",
        "      # the `...` part)\n",
        "      actions = np.array([ np.random.randint(envs.single_action_space.n) for _ in range(envs.num_envs)])\n",
        "    else:\n",
        "      q_values = q_network(torch.Tensor(obs).to(device))\n",
        "      # TODO-Done: Select the action with the highest Q-value from q_values\n",
        "      actions = np.array([int(q_values.argmax().cpu())])\n",
        "\n",
        "    # TRY NOT TO MODIFY: execute the game and log data.\n",
        "    next_obs, rewards, terminations, truncations, infos = envs.step(actions)\n",
        "\n",
        "    # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
        "    if \"final_info\" in infos:\n",
        "        for info in infos[\"final_info\"]:\n",
        "            if info and \"episode\" in info:\n",
        "                print(f\"global_step={global_step}, episodic_return={info['episode']['r']}\")\n",
        "                writer.add_scalar(\"charts/episodic_return\", info[\"episode\"][\"r\"], global_step)\n",
        "                writer.add_scalar(\"charts/episodic_length\", info[\"episode\"][\"l\"], global_step)\n",
        "\n",
        "    # TRY NOT TO MODIFY: save data to reply buffer; handle `final_observation`\n",
        "    real_next_obs = next_obs.copy()\n",
        "    for idx, trunc in enumerate(truncations):\n",
        "        if trunc:\n",
        "            real_next_obs[idx] = infos[\"final_observation\"][idx]\n",
        "    rb.add(obs, real_next_obs, actions, rewards, terminations, infos)\n",
        "\n",
        "    # TRY NOT TO MODIFY: CRUCIAL step easy to overlook\n",
        "    obs = next_obs\n",
        "\n",
        "    # ALGO LOGIC: training.\n",
        "    if global_step > args.learning_starts:\n",
        "        if global_step % args.train_frequency == 0:\n",
        "            data = rb.sample(args.batch_size)\n",
        "            with torch.no_grad():\n",
        "                target_max, _ = target_network(data.next_observations.float()).max(dim=1)\n",
        "                # TODO-Done: Calculate the TD target using the Bellman equation\n",
        "                # Hint: The formula is R + γ * max_a' Q_target(S', a')\n",
        "                # Hint2: data.dones.flatten() contains whether we reached\n",
        "                #        a terminal state, where the future reward is 0.\n",
        "                # Hint3: reduce `args.learning_starts` to a low value for\n",
        "                #        testing. Otherwise, you have to train for 10k steps\n",
        "                #        to see if your td_target implemention works\n",
        "                td_target = data.rewards.squeeze() + args.gamma * target_max * (1 - data.dones.flatten().to(torch.float32))\n",
        "                td_target = td_target.squeeze()\n",
        "\n",
        "            old_val = q_network(data.observations.float()).gather(1, data.actions).squeeze()\n",
        "\n",
        "            # TODO-Done: Calculate the loss\n",
        "            # Hint: DQN uses the Mean Squared Error (MSE) loss between the TD target and the predicted Q-value.\n",
        "            loss = torch.mean((td_target - old_val) ** 2)\n",
        "\n",
        "            if global_step % 100 == 0:\n",
        "                writer.add_scalar(\"losses/td_loss\", loss, global_step)\n",
        "                writer.add_scalar(\"losses/q_values\", old_val.mean().item(), global_step)\n",
        "\n",
        "            # optimize the model\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # update target network\n",
        "        if global_step % args.target_network_frequency == 0:\n",
        "            for target_network_param, q_network_param in zip(target_network.parameters(), q_network.parameters()):\n",
        "                # TODO-Done: Perform a soft update of the target network's weights\n",
        "                # Hint: The formula is τ * Q_network_weights + (1 - τ) * Q_target_weights\n",
        "                target_network_param.data.copy_(args.tau * q_network_param + (1 - args.tau) * target_network_param)"
      ],
      "metadata": {
        "id": "7t4dlSemfYPw",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "Now it is time to test how well our trained agent performs. To get a measure of its capabilities, we evaluate it in a separate test environment without the random exploration used during training. In other words, we set ϵ=0, meaning the agent will always choose the action it believes will yield the highest reward (this is called a greedy or deterministic policy).\n",
        "\n",
        "We then run the agent for a set number of test episodes (`eval_episodes`) and calculate the average reward per episode. This average gives us an estimate of the agent's performance.\n",
        "\n",
        "**Note on best practices:** To keep it simple, in this exercise, we evaluate the agent once after training has finished. However, a much better practice is to evaluate the agent periodically during training (e.g., every 1000 steps). This allows you to track learning progress over time, diagnose problems, and save the model at its peak performance.\n",
        "\n",
        "For a reliable performance measure, an agent must be trained multiple times using different random seeds (e.g., 10 runs). Averaging these results provides a robust estimate of its true capabilities. While we omit this step for simplicity, it is essential for your future projects!\n",
        "\n",
        "Please also note all the differences from the CleanRL evaluation code in the cell below."
      ],
      "metadata": {
        "id": "f7MD4uI_Io-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code adapted from https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl_utils/evals/dqn_eval.py\n",
        "\n",
        "def evaluate(\n",
        "    model_path: str,\n",
        "    make_env: Callable,\n",
        "    eval_episodes: int,\n",
        "    run_name: str,\n",
        "    Model: torch.nn.Module,\n",
        "    device: torch.device = torch.device(\"cpu\"),\n",
        "    epsilon: float = 0.00,\n",
        "    capture_video: bool = True,\n",
        "):\n",
        "\n",
        "    episodic_returns = []\n",
        "    for i in range(eval_episodes):\n",
        "      episode_done = False\n",
        "\n",
        "      # Unlike CleanRL, we have a different seed for each environment,\n",
        "      # where each seed is different from those seen during training\n",
        "      envs = gym.vector.SyncVectorEnv([make_env(max_time_steps=args.max_time_steps,\n",
        "                                                seed=args.seed+i+42,\n",
        "                                                num_scramble_steps=args.num_scramble_steps)])\n",
        "      model = Model(envs).to(device)\n",
        "      model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "      model.eval()\n",
        "      obs, _ = envs.reset()\n",
        "\n",
        "      while not episode_done:\n",
        "        if random.random() < epsilon:\n",
        "            # !!! While the CleanRL repo has a non-zero default noise,\n",
        "            # you should have a zero epsilon!\n",
        "            raise NotImplementedError(\"Evaluation should have no noise!\")\n",
        "        else:\n",
        "            q_values = model(torch.Tensor(obs).to(device))\n",
        "            actions = torch.argmax(q_values, dim=1).cpu().numpy()\n",
        "        next_obs, rewards, terminations, truncations, infos = envs.step(actions)\n",
        "\n",
        "        if \"final_info\" in infos:\n",
        "            for info in infos[\"final_info\"]:\n",
        "                if \"episode\" not in info:\n",
        "                    continue\n",
        "                print(f\"eval_episode={len(episodic_returns)}, episodic_return={info['episode']['r']}\")\n",
        "                episodic_returns += [info[\"episode\"][\"r\"]]\n",
        "                episode_done = True\n",
        "        obs = next_obs\n",
        "\n",
        "    return episodic_returns"
      ],
      "metadata": {
        "id": "FLtosT7WIsv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We first save the trained model at the end of training and then evaluate it using the function above\n",
        "model_path = f\"runs/{run_name}/{args.exp_name}.cleanrl_model\"\n",
        "torch.save(q_network.state_dict(), model_path)\n",
        "print(f\"model saved to {model_path}\")\n",
        "\n",
        "episodic_returns = evaluate(\n",
        "            model_path,\n",
        "            make_env,\n",
        "            eval_episodes=10,\n",
        "            run_name=f\"{run_name}-eval\",\n",
        "            Model=QNetwork,\n",
        "            device=device,\n",
        "        )\n",
        "for idx, episodic_return in enumerate(episodic_returns):\n",
        "  writer.add_scalar(\"eval/episodic_return\", episodic_return, idx)"
      ],
      "metadata": {
        "id": "rgzxKMO7QR7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While we above get 10 different returns, we are interested in knowing how our single agent is doing. We thus compute the average and standard deviation of these values."
      ],
      "metadata": {
        "id": "69Jf5wcM6b1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"mean returns: {np.mean(episodic_returns)}\")\n",
        "print(f\"standard devision of returns: {np.std(episodic_returns)}\")"
      ],
      "metadata": {
        "id": "4jH98j246r-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note on evaluation:** while we here used standard deviation, there are many more metrics we could use, depending on the question we are asking. `TODO` familiarise yourself with the concepts of:\n",
        "\n",
        "\n",
        "*   Standard deviation\n",
        "*   Standard error\n",
        "*   Confidence intervals\n",
        "*   Interquartile Mean (IQM)\n",
        "\n",
        "Ensure you have also read \"Deep Reinforcement Learning at the Edge of the Statistical Precipice\" (https://arxiv.org/abs/2108.13264), which is one of the required readings!\n"
      ],
      "metadata": {
        "id": "wX6Du8wU0hG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing Training Progress: Learning Curves\n",
        "\n",
        "We have code to train and evaluate our agent, but how can we tell if (and how well) it is learning over time?\n",
        "\n",
        "The most important tool for monitoring this is the learning curve. A learning curve is a graph that plots the agent's performance (like its episodic returns) against the number of training steps.\n",
        "\n",
        "Visualising a learning curve is useful for seeing whether the agent is improving and diagnosing training issues (e.g., a flat curve means the agent is not learning).\n",
        "\n",
        "In this class, we will use TensorBoard to plot our learning curves. Other excellent tools for this purpose include [Weights & Biases](https://wandb.ai/site).\n"
      ],
      "metadata": {
        "id": "Rz_v-FxQJGDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"runs\""
      ],
      "metadata": {
        "id": "exDxmaIlbtFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we trained our agent and saw it learnt we can close the tensorboard writer."
      ],
      "metadata": {
        "id": "crAWArG-I_tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer.close()"
      ],
      "metadata": {
        "id": "yF0fLyGOI_Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next: Your turn!"
      ],
      "metadata": {
        "id": "y_T89AccZ2le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, the agent has learned to solve the cube when it is only two steps away from the goal. That is a great start! But what happens when the problem gets harder?\n",
        "\n",
        "First, as an experiment, try setting `num_scramble_steps=30` in the Args class and see how the agent performs.\n",
        "\n",
        "You will likely observe that the agent struggles to learn anything meaningful. This is a classic challenge in Reinforcement Learning! The agent is grappling with the cube's **high-dimensionality** (a vast number of possible states), the **long-horizon** nature of the task (requiring a long sequence of correct moves to reach the goal), and **sparse rewards** (we only know if an action was useful when we solve some parts of the cube).\n",
        "\n",
        "------\n",
        "## Your challenge\n",
        "\n",
        "Your main challenge is to improve the existing code to solve a cube scrambled with the highest `num_scramble_steps` value you can achieve.\n",
        "\n",
        "You do **NOT** need to reach a huge number. Solving the cube from 7-10 steps away would be a very good result. The primary goal of this exercise is for you to experiment with different RL components and build an intuition for how they work.\n",
        "\n",
        "Here are some ideas you could consider to get started:\n",
        "- Update the replay buffer to have smarter sampling strategy. Popular options include Prioritized Experience Replay (PER; https://arxiv.org/pdf/1511.05952) and Hindsight Experience Replay (HER; https://arxiv.org/abs/1707.01495)\n",
        "- Train the agent with a \"curriculum\" , where the agent first masters solving the cube from 1 move away, then 2, then 3, and so on (https://dl.acm.org/doi/pdf/10.1145/1553374.1553380)\n",
        "- Change the hyperparameters in the `Args` class. The `learning_rate`, `exploration_fraction`, and `max_time_steps` are a good start.\n",
        "- Beyond the replay buffer, the other core component of DQN is the target network. Familiarise yourself with the idea of a target network and what it does, change its update frequency, etc. The first two pages of the paper that introduced Double DQN (https://arxiv.org/pdf/1509.06461) could be usful. The goal here is not to implement Double DQN, but to use the paper's introduction to grasp the critical role of the target network and the potential issues in the standard DQN algorithm we cover in this course.\n",
        "\n",
        "\n",
        "Finally, please write down a summary of your experience. The in-class discussion will be based on these notes, so be sure to include:\n",
        "- What you tried, even if it failed.\n",
        "- The challenges you faced.\n",
        "- What you learned about the problem, the RL techniques, or any other thoughts you had.\n",
        "\n",
        "If you have any feedback regarding this exercise or the course, please submit this (anonynous) form. https://forms.gle/71gj9p8mX91f1sLE6\n"
      ],
      "metadata": {
        "id": "oNd9OdIEJfff"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "YvyGCsgSCxHQ",
        "ImoMstr8lmQl"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}